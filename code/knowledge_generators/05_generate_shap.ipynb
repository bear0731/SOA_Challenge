{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05. Generate SHAP Analysis\n",
                "\n",
                "計算 SHAP 值用於模型可解釋性。\n",
                "\n",
                "**兩層輸出：**\n",
                "- **Global SHAP**: 整體特徵重要性 → 放入 System Prompt\n",
                "- **Local SHAP Examples**: 典型案例的 SHAP 分解 → 供 RAG 參考"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import os\n",
                "import lightgbm as lgb\n",
                "import shap\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Paths\n",
                "DATA_PATH = '../../data/ilec_cleaned.parquet'\n",
                "MODEL_PATH = '../../models/lgbm_mortality_offset_poisson.txt'\n",
                "OUTPUT_DIR = '../../knowledge_base/shap'\n",
                "\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print('Setup complete')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data (smaller sample for SHAP - 1%)\n",
                "print('Loading data...')\n",
                "df_full = pd.read_parquet(DATA_PATH)\n",
                "print(f'Full data: {len(df_full):,} rows')\n",
                "\n",
                "# 1% sample for SHAP (SHAP is computationally expensive)\n",
                "df = df_full.sample(frac=0.01, random_state=42).reset_index(drop=True)\n",
                "print(f'Sampled 1%: {len(df):,} rows')\n",
                "del df_full"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model\n",
                "print('Loading LightGBM model...')\n",
                "model = lgb.Booster(model_file=MODEL_PATH)\n",
                "print(f'Model loaded: {model.num_trees()} trees')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features\n",
                "FEATURES = ['Attained_Age', 'Issue_Age', 'Duration', 'Sex', 'Smoker_Status', \n",
                "            'Insurance_Plan', 'Face_Amount_Band', 'Preferred_Class', \n",
                "            'SOA_Post_Lvl_Ind', 'SOA_Antp_Lvl_TP', 'SOA_Guar_Lvl_TP']\n",
                "\n",
                "CATEGORICAL = ['Sex', 'Smoker_Status', 'Insurance_Plan', 'Face_Amount_Band', \n",
                "               'Preferred_Class', 'SOA_Post_Lvl_Ind', 'SOA_Antp_Lvl_TP', 'SOA_Guar_Lvl_TP']\n",
                "\n",
                "# Encode\n",
                "X = df[FEATURES].copy()\n",
                "encoders = {}\n",
                "for col in CATEGORICAL:\n",
                "    le = LabelEncoder()\n",
                "    X[col] = le.fit_transform(X[col].astype(str))\n",
                "    encoders[col] = le\n",
                "\n",
                "# Save encoders for later use\n",
                "encoder_mappings = {}\n",
                "for col, le in encoders.items():\n",
                "    encoder_mappings[col] = {str(i): str(c) for i, c in enumerate(le.classes_)}\n",
                "\n",
                "print(f'Features prepared: {X.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Global SHAP"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create SHAP explainer\n",
                "print('Creating SHAP explainer...')\n",
                "explainer = shap.TreeExplainer(model)\n",
                "\n",
                "# Calculate SHAP values (this may take a few minutes)\n",
                "print('Calculating SHAP values (this may take a few minutes)...')\n",
                "shap_values = explainer.shap_values(X.values)\n",
                "print(f'SHAP values shape: {shap_values.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Global feature importance\n",
                "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': FEATURES,\n",
                "    'mean_abs_shap': mean_abs_shap\n",
                "}).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)\n",
                "\n",
                "feature_importance['rank'] = range(1, len(feature_importance) + 1)\n",
                "feature_importance['pct_contribution'] = (feature_importance['mean_abs_shap'] / \n",
                "                                          feature_importance['mean_abs_shap'].sum() * 100)\n",
                "\n",
                "print('=== Global Feature Importance (SHAP) ===')\n",
                "print(feature_importance.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save global importance\n",
                "base_value = float(explainer.expected_value)\n",
                "\n",
                "global_shap = {\n",
                "    \"description\": \"Global SHAP feature importance for mortality prediction model\",\n",
                "    \"base_value\": round(base_value, 6),\n",
                "    \"base_value_interpretation\": f\"Average predicted mortality rate: {base_value:.6f}\",\n",
                "    \"sample_size\": len(df),\n",
                "    \"feature_importance\": []\n",
                "}\n",
                "\n",
                "for _, row in feature_importance.iterrows():\n",
                "    global_shap[\"feature_importance\"].append({\n",
                "        \"feature\": row['feature'],\n",
                "        \"rank\": int(row['rank']),\n",
                "        \"mean_abs_shap\": round(row['mean_abs_shap'], 6),\n",
                "        \"pct_contribution\": round(row['pct_contribution'], 2)\n",
                "    })\n",
                "\n",
                "with open(f'{OUTPUT_DIR}/global_importance.json', 'w') as f:\n",
                "    json.dump(global_shap, f, indent=2)\n",
                "\n",
                "print(f'✓ global_importance.json saved')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SHAP summary plot\n",
                "plt.figure(figsize=(10, 8))\n",
                "shap.summary_plot(shap_values, X, feature_names=FEATURES, show=False)\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUTPUT_DIR}/shap_summary_plot.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f'✓ shap_summary_plot.png saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Local SHAP Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create typical case examples\n",
                "# High risk case\n",
                "high_risk_idx = df[df['Death_Count'] > 0].sample(1, random_state=42).index[0]\n",
                "\n",
                "# Low risk case (young, non-smoker)\n",
                "low_risk_mask = (df['Attained_Age'] < 40) & (df['Smoker_Status'] == 'NS') & (df['Death_Count'] == 0)\n",
                "low_risk_idx = df[low_risk_mask].sample(1, random_state=42).index[0]\n",
                "\n",
                "# Average case\n",
                "avg_age = df['Attained_Age'].median()\n",
                "avg_mask = (df['Attained_Age'] >= avg_age - 5) & (df['Attained_Age'] <= avg_age + 5)\n",
                "avg_idx = df[avg_mask].sample(1, random_state=42).index[0]\n",
                "\n",
                "example_indices = {\n",
                "    'high_risk': high_risk_idx,\n",
                "    'low_risk': low_risk_idx,\n",
                "    'average': avg_idx\n",
                "}\n",
                "\n",
                "print('Example indices selected:')\n",
                "for name, idx in example_indices.items():\n",
                "    print(f'  {name}: index {idx}, Age={df.loc[idx, \"Attained_Age\"]}, Smoker={df.loc[idx, \"Smoker_Status\"]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate local SHAP for each example\n",
                "local_examples = []\n",
                "\n",
                "for case_name, idx in example_indices.items():\n",
                "    # Get original values\n",
                "    original_row = df.loc[idx, FEATURES].to_dict()\n",
                "    \n",
                "    # Get encoded values\n",
                "    encoded_row = X.loc[idx].values\n",
                "    \n",
                "    # Get prediction\n",
                "    prediction = model.predict([encoded_row])[0]\n",
                "    \n",
                "    # Get SHAP values for this row\n",
                "    row_shap = shap_values[df.index.get_loc(idx)]\n",
                "    \n",
                "    # Build SHAP breakdown\n",
                "    shap_breakdown = []\n",
                "    for i, feat in enumerate(FEATURES):\n",
                "        shap_breakdown.append({\n",
                "            \"feature\": feat,\n",
                "            \"value\": str(original_row[feat]),\n",
                "            \"shap_value\": round(float(row_shap[i]), 6),\n",
                "            \"direction\": \"increases\" if row_shap[i] > 0 else \"decreases\"\n",
                "        })\n",
                "    \n",
                "    # Sort by absolute SHAP value\n",
                "    shap_breakdown = sorted(shap_breakdown, key=lambda x: abs(x['shap_value']), reverse=True)\n",
                "    \n",
                "    # Top drivers\n",
                "    top_drivers = shap_breakdown[:3]\n",
                "    \n",
                "    example = {\n",
                "        \"case_type\": case_name,\n",
                "        \"input\": original_row,\n",
                "        \"prediction\": round(float(prediction), 6),\n",
                "        \"base_value\": round(base_value, 6),\n",
                "        \"shap_breakdown\": shap_breakdown,\n",
                "        \"top_drivers\": top_drivers,\n",
                "        \"explanation\": f\"Predicted mortality rate: {prediction:.6f}. \"\n",
                "                       f\"Main drivers: {top_drivers[0]['feature']} ({top_drivers[0]['direction']} risk), \"\n",
                "                       f\"{top_drivers[1]['feature']} ({top_drivers[1]['direction']} risk).\"\n",
                "    }\n",
                "    \n",
                "    local_examples.append(example)\n",
                "    \n",
                "    print(f\"\\n=== {case_name.upper()} ===\")\n",
                "    print(f\"Prediction: {prediction:.6f}\")\n",
                "    print(f\"Top 3 drivers:\")\n",
                "    for d in top_drivers:\n",
                "        print(f\"  {d['feature']}: {d['value']} → SHAP={d['shap_value']:+.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save local examples\n",
                "local_shap = {\n",
                "    \"description\": \"Local SHAP examples for typical cases\",\n",
                "    \"base_value\": round(base_value, 6),\n",
                "    \"examples\": local_examples\n",
                "}\n",
                "\n",
                "with open(f'{OUTPUT_DIR}/local_examples.json', 'w') as f:\n",
                "    json.dump(local_shap, f, indent=2)\n",
                "\n",
                "print(f'\\n✓ local_examples.json saved')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Waterfall plot for high risk case\n",
                "high_risk_loc = df.index.get_loc(high_risk_idx)\n",
                "shap.plots.waterfall(shap.Explanation(\n",
                "    values=shap_values[high_risk_loc],\n",
                "    base_values=base_value,\n",
                "    data=X.iloc[high_risk_loc].values,\n",
                "    feature_names=FEATURES\n",
                "), show=False)\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUTPUT_DIR}/shap_waterfall_high_risk.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f'✓ shap_waterfall_high_risk.png saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('='*60)\n",
                "print('SHAP ANALYSIS COMPLETE')\n",
                "print('='*60)\n",
                "print(f'\\nBase value (avg prediction): {base_value:.6f}')\n",
                "print(f'\\nTop 5 Features by Importance:')\n",
                "for i, row in feature_importance.head(5).iterrows():\n",
                "    print(f\"  {row['rank']}. {row['feature']}: {row['pct_contribution']:.1f}%\")\n",
                "\n",
                "print(f'\\nGenerated files:')\n",
                "print(f'  ✓ global_importance.json')\n",
                "print(f'  ✓ local_examples.json')\n",
                "print(f'  ✓ shap_summary_plot.png')\n",
                "print(f'  ✓ shap_waterfall_high_risk.png')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}