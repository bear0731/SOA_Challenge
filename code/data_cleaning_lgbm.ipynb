{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6a4fce35",
            "metadata": {},
            "source": [
                "# ILEC Data Cleaning for Two-Stage LGBM Mortality Prediction\n",
                "\n",
                "This notebook prepares the ILEC 2012-2019 mortality dataset for two-stage LGBM modeling.\n",
                "\n",
                "## Two-Stage Strategy\n",
                "- **Stage 1**: Baseline model with 11 core features (no Year)\n",
                "- **Stage 2**: Residual analysis using Observation_Year\n",
                "\n",
                "```\n",
                "Stage 1: baseline_pred = model(Age, Sex, Smoker, etc.)\n",
                "         ↓\n",
                "Stage 2: residual = observed - baseline → analyze by Year\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "ad77483e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Setup complete!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# File paths\n",
                "DATA_PATH = '../data/ILEC_2012_19 - 20240429.txt'\n",
                "OUTPUT_PATH = '../data/ilec_cleaned.parquet'\n",
                "CHUNK_SIZE = 500000\n",
                "\n",
                "print('Setup complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ce673d1",
            "metadata": {},
            "source": [
                "## 1. Define Feature Strategy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1835e15",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Stage 1 Features: 11\n",
                        "  Numerical (3): ['Attained_Age', 'Issue_Age', 'Duration']\n",
                        "  Categorical (8): ['Sex', 'Smoker_Status', 'Insurance_Plan', 'Face_Amount_Band', 'Preferred_Class', 'SOA_Post_Lvl_Ind', 'SOA_Antp_Lvl_TP', 'SOA_Guar_Lvl_TP']\n",
                        "\n",
                        "Stage 2 Features: ['Observation_Year']\n",
                        "\n",
                        "Target: Death_Count\n",
                        "Weight: Policies_Exposed\n"
                    ]
                }
            ],
            "source": [
                "# ========================================\n",
                "# Stage 1 Features (11 total, NO Year)\n",
                "# ========================================\n",
                "\n",
                "NUMERICAL_FEATURES = [\n",
                "    'Attained_Age',\n",
                "    'Issue_Age', \n",
                "    'Duration'\n",
                "]\n",
                "\n",
                "CATEGORICAL_FEATURES = [\n",
                "    'Sex',\n",
                "    'Smoker_Status',\n",
                "    'Insurance_Plan',\n",
                "    'Face_Amount_Band',\n",
                "    'Preferred_Class',      # Fill NA with 'NA'\n",
                "    'SOA_Post_Lvl_Ind',     # Fill NA with 'NA'\n",
                "    'SOA_Antp_Lvl_TP',\n",
                "    'SOA_Guar_Lvl_TP'\n",
                "]\n",
                "\n",
                "# ========================================\n",
                "# Stage 2: Year for residual analysis\n",
                "# ========================================\n",
                "STAGE2_FEATURES = ['Observation_Year']\n",
                "\n",
                "# Columns to fill NA with 'NA' category\n",
                "FILL_NA_COLS = ['Preferred_Class', 'SOA_Post_Lvl_Ind']\n",
                "\n",
                "# Target and weight\n",
                "TARGET = 'Death_Count'\n",
                "WEIGHT = 'Policies_Exposed'\n",
                "\n",
                "# All columns to read\n",
                "STAGE1_FEATURES = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
                "USE_COLS = STAGE1_FEATURES + STAGE2_FEATURES + [TARGET, WEIGHT]\n",
                "\n",
                "print(f'Stage 1 Features: {len(STAGE1_FEATURES)}')\n",
                "print(f'  Numerical ({len(NUMERICAL_FEATURES)}): {NUMERICAL_FEATURES}')\n",
                "print(f'  Categorical ({len(CATEGORICAL_FEATURES)}): {CATEGORICAL_FEATURES}')\n",
                "print(f'\\nStage 2 Features: {STAGE2_FEATURES}')\n",
                "print(f'\\nTarget: {TARGET}')\n",
                "print(f'Weight: {WEIGHT}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "98e3a896",
            "metadata": {},
            "source": [
                "## 2. Load and Clean Data (Chunk-based)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "7002444e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting data loading and cleaning...\n",
                        "============================================================\n",
                        "  Processed 10 chunks (5,000,000 records)\n",
                        "  Processed 20 chunks (10,000,000 records)\n",
                        "  Processed 30 chunks (15,000,000 records)\n",
                        "  Processed 40 chunks (20,000,000 records)\n",
                        "  Processed 50 chunks (25,000,000 records)\n",
                        "  Processed 60 chunks (30,000,000 records)\n",
                        "  Processed 70 chunks (35,000,000 records)\n",
                        "  Processed 80 chunks (40,000,000 records)\n",
                        "  Processed 90 chunks (45,000,000 records)\n",
                        "\n",
                        "Loading complete! Total: 45,501,036 records\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "print('Starting data loading and cleaning...')\n",
                "print('=' * 60)\n",
                "\n",
                "cleaned_chunks = []\n",
                "chunk_num = 0\n",
                "total_rows = 0\n",
                "\n",
                "for chunk in pd.read_csv(DATA_PATH, sep='\\t', chunksize=CHUNK_SIZE, usecols=USE_COLS):\n",
                "    chunk_num += 1\n",
                "    total_rows += len(chunk)\n",
                "    \n",
                "    # Fill NA for specified columns\n",
                "    for col in FILL_NA_COLS:\n",
                "        chunk[col] = chunk[col].fillna('NA').astype(str)\n",
                "    \n",
                "    # Convert categorical columns to category dtype\n",
                "    for col in CATEGORICAL_FEATURES:\n",
                "        chunk[col] = chunk[col].astype('category')\n",
                "    \n",
                "    cleaned_chunks.append(chunk)\n",
                "    \n",
                "    if chunk_num % 10 == 0:\n",
                "        print(f'  Processed {chunk_num} chunks ({total_rows:,} records)')\n",
                "\n",
                "print(f'\\nLoading complete! Total: {total_rows:,} records')\n",
                "print('=' * 60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "abc0eee3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Combining chunks...\n",
                        "Combined DataFrame shape: (45501036, 14)\n",
                        "Memory usage: 22.75 GB\n"
                    ]
                }
            ],
            "source": [
                "# Combine all chunks\n",
                "print('Combining chunks...')\n",
                "df = pd.concat(cleaned_chunks, ignore_index=True)\n",
                "del cleaned_chunks  # Free memory\n",
                "\n",
                "print(f'Combined DataFrame shape: {df.shape}')\n",
                "print(f'Memory usage: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "313b542b",
            "metadata": {},
            "source": [
                "## 3. Data Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "9f39f631",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Data Validation ===\n",
                        "\n",
                        "Shape: (45501036, 14)\n",
                        "\n",
                        "Column dtypes:\n",
                        "Observation_Year      int64\n",
                        "Sex                  object\n",
                        "Smoker_Status        object\n",
                        "Insurance_Plan       object\n",
                        "Issue_Age             int64\n",
                        "Duration              int64\n",
                        "Face_Amount_Band     object\n",
                        "Attained_Age          int64\n",
                        "SOA_Antp_Lvl_TP      object\n",
                        "SOA_Guar_Lvl_TP      object\n",
                        "SOA_Post_Lvl_Ind     object\n",
                        "Preferred_Class      object\n",
                        "Policies_Exposed    float64\n",
                        "Death_Count           int64\n",
                        "dtype: object\n",
                        "\n",
                        "Missing values:\n",
                        "Observation_Year    0\n",
                        "Sex                 0\n",
                        "Smoker_Status       0\n",
                        "Insurance_Plan      0\n",
                        "Issue_Age           0\n",
                        "Duration            0\n",
                        "Face_Amount_Band    0\n",
                        "Attained_Age        0\n",
                        "SOA_Antp_Lvl_TP     0\n",
                        "SOA_Guar_Lvl_TP     0\n",
                        "SOA_Post_Lvl_Ind    0\n",
                        "Preferred_Class     0\n",
                        "Policies_Exposed    0\n",
                        "Death_Count         0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print('=== Data Validation ===')\n",
                "print(f'\\nShape: {df.shape}')\n",
                "print(f'\\nColumn dtypes:')\n",
                "print(df.dtypes)\n",
                "print(f'\\nMissing values:')\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "707f3ddd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Numerical Feature Statistics ===\n",
                        "       Attained_Age     Issue_Age      Duration\n",
                        "count  4.550104e+07  4.550104e+07  4.550104e+07\n",
                        "mean   5.294412e+01  4.026115e+01  1.368296e+01\n",
                        "std    1.764405e+01  1.674750e+01  1.044001e+01\n",
                        "min    0.000000e+00  0.000000e+00  1.000000e+00\n",
                        "25%    4.100000e+01  2.900000e+01  6.000000e+00\n",
                        "50%    5.300000e+01  4.000000e+01  1.200000e+01\n",
                        "75%    6.500000e+01  5.200000e+01  1.900000e+01\n",
                        "max    1.200000e+02  1.000000e+02  1.190000e+02\n"
                    ]
                }
            ],
            "source": [
                "# Numerical statistics\n",
                "print('=== Numerical Feature Statistics ===')\n",
                "print(df[NUMERICAL_FEATURES].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "fc615484",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Categorical Feature Distributions ===\n",
                        "\n",
                        "Sex:\n",
                        "Sex\n",
                        "M    24333152\n",
                        "F    21167884\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Smoker_Status:\n",
                        "Smoker_Status\n",
                        "NS    32872436\n",
                        "S      8695643\n",
                        "U      3932957\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Insurance_Plan:\n",
                        "Insurance_Plan\n",
                        "Term     20929192\n",
                        "Perm      7470281\n",
                        "UL        6075946\n",
                        "ULSG      4613219\n",
                        "VL        3120515\n",
                        "VLSG      2412344\n",
                        "Other      879539\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Face_Amount_Band:\n",
                        "Face_Amount_Band\n",
                        "05: 100,000 - 249,999        10118882\n",
                        "06: 250,000 - 499,999         7396842\n",
                        "04: 50,000 - 99,999           6460460\n",
                        "07: 500,000 - 999,999         5471458\n",
                        "03: 25,000 - 49,999           4619883\n",
                        "08: 1,000,000 - 2,499,999     3919912\n",
                        "02: 10,000 - 24,999           3030835\n",
                        "01: 0 - 9,999                 2269246\n",
                        "09: 2,500,000 - 4,999,999     1204673\n",
                        "10: 5,000,000 - 9,999,999      676346\n",
                        "Name: count, dtype: int64\n",
                        "  ... (11 unique values)\n",
                        "\n",
                        "Preferred_Class:\n",
                        "Preferred_Class\n",
                        "NA     14615884\n",
                        "2.0     7417733\n",
                        "1.0     7172721\n",
                        "2       4015772\n",
                        "1       3792389\n",
                        "3.0     3538797\n",
                        "3       1969016\n",
                        "4.0     1285892\n",
                        "4        894371\n",
                        "U        798461\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "SOA_Post_Lvl_Ind:\n",
                        "SOA_Post_Lvl_Ind\n",
                        "NA     24571844\n",
                        "WLT    13384712\n",
                        "ULT     3660732\n",
                        "PLT     3109964\n",
                        "NLT      773784\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "SOA_Antp_Lvl_TP:\n",
                        "SOA_Antp_Lvl_TP\n",
                        "N/A (Not Term)       24571844\n",
                        "20 yr anticipated     5190317\n",
                        "Unknown               3883107\n",
                        "10 yr anticipated     3774124\n",
                        "15 yr anticipated     3114665\n",
                        "30 yr anticipated     2527808\n",
                        " 5 yr anticipated     1034572\n",
                        "25 yr anticipated      853106\n",
                        "Not Level Term         551409\n",
                        "40 yr anticipated          84\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "SOA_Guar_Lvl_TP:\n",
                        "SOA_Guar_Lvl_TP\n",
                        "N/A (Not Term)      24571844\n",
                        "20 yr guaranteed     4762703\n",
                        "10 yr guaranteed     4500502\n",
                        "Unknown              3883107\n",
                        "15 yr guaranteed     3048389\n",
                        "30 yr guaranteed     2002577\n",
                        " 5 yr guaranteed     1550115\n",
                        "25 yr guaranteed      630306\n",
                        "Not Level Term        551409\n",
                        "40 yr guaranteed          84\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Categorical distributions\n",
                "print('=== Categorical Feature Distributions ===')\n",
                "for col in CATEGORICAL_FEATURES:\n",
                "    print(f'\\n{col}:')\n",
                "    vc = df[col].value_counts()\n",
                "    if len(vc) > 10:\n",
                "        print(vc.head(10))\n",
                "        print(f'  ... ({len(vc)} unique values)')\n",
                "    else:\n",
                "        print(vc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "a98c6de5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Observation_Year Distribution (for Stage 2) ===\n",
                        "Observation_Year\n",
                        "2012    4273432\n",
                        "2013    4608378\n",
                        "2014    4877434\n",
                        "2015    4998104\n",
                        "2016    5119495\n",
                        "2017    5293054\n",
                        "2018    8122436\n",
                        "2019    8208703\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Stage 2: Year distribution\n",
                "print('=== Observation_Year Distribution (for Stage 2) ===')\n",
                "print(df['Observation_Year'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "64c2e3cf",
            "metadata": {},
            "source": [
                "## 4. Save Cleaned Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "50a3e699",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving cleaned data to ../data/ilec_cleaned.parquet...\n",
                        "Saved! File size: 0.29 GB\n",
                        "Verification - Shape: (45501036, 14)\n",
                        "\n",
                        "Data cleaning complete!\n"
                    ]
                }
            ],
            "source": [
                "# Save as parquet (efficient for large datasets)\n",
                "print(f'Saving cleaned data to {OUTPUT_PATH}...')\n",
                "df.to_parquet(OUTPUT_PATH, index=False)\n",
                "\n",
                "# Verify saved file\n",
                "file_size = Path(OUTPUT_PATH).stat().st_size / 1e9\n",
                "print(f'Saved! File size: {file_size:.2f} GB')\n",
                "\n",
                "# Quick verification\n",
                "df_verify = pd.read_parquet(OUTPUT_PATH)\n",
                "print(f'Verification - Shape: {df_verify.shape}')\n",
                "print('\\nData cleaning complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d66c472f",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "### Two-Stage Modeling Architecture\n",
                "\n",
                "| Stage | Purpose | Features |\n",
                "|-------|---------|----------|\n",
                "| **Stage 1** | Baseline mortality prediction | 11 core features (no Year) |\n",
                "| **Stage 2** | Residual analysis | Observation_Year |\n",
                "\n",
                "### Stage 1 Features (11)\n",
                "| Type | Count | Features |\n",
                "|------|-------|----------|\n",
                "| Numerical | 3 | Attained_Age, Issue_Age, Duration |\n",
                "| Categorical | 8 | Sex, Smoker_Status, Insurance_Plan, Face_Amount_Band, Preferred_Class, SOA_Post_Lvl_Ind, SOA_Antp_Lvl_TP, SOA_Guar_Lvl_TP |\n",
                "\n",
                "### Target & Weight\n",
                "- **Target**: Death_Count\n",
                "- **Weight**: Policies_Exposed\n",
                "\n",
                "### Processing Applied\n",
                "- Filled NA → 'NA' category for: Preferred_Class, SOA_Post_Lvl_Ind\n",
                "- Converted categorical columns to category dtype\n",
                "- Saved as parquet format\n",
                "\n",
                "### Next Steps\n",
                "1. Train Stage 1 model (LGBM Poisson)\n",
                "2. Calculate residuals\n",
                "3. Analyze residual patterns by Observation_Year"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
