{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LightGBM Model Explainability & Visualization\n",
                "\n",
                "Comprehensive analysis for the LightGBM mortality prediction model:\n",
                "\n",
                "1. **Feature Importance** (Gain, Split)\n",
                "2. **Tree Structure Visualization**\n",
                "3. **SHAP-style Analysis** (Using LGB native methods)\n",
                "4. **Partial Dependence Plots**\n",
                "5. **Interaction Effects**\n",
                "6. **Year Trend Factors**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import lightgbm as lgb\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "print('Libraries loaded!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Model and Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load trained model\n",
                "model = lgb.Booster(model_file='../models/lgbm_mortality_offset_poisson.txt')\n",
                "print(f'Model loaded with {model.num_trees()} trees')\n",
                "\n",
                "# Load year factors\n",
                "year_factors = pd.read_csv('../models/year_factors_offset.csv')\n",
                "print('Year factors:')\n",
                "display(year_factors)\n",
                "\n",
                "# Load data\n",
                "df = pd.read_parquet('../data/ilec_cleaned.parquet')\n",
                "print(f'\\nData shape: {df.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature setup matching training\n",
                "NUMERICAL_FEATURES = ['Attained_Age', 'Issue_Age', 'Duration']\n",
                "CATEGORICAL_FEATURES = [\n",
                "    'Sex', 'Smoker_Status', 'Insurance_Plan', 'Face_Amount_Band',\n",
                "    'Preferred_Class', 'SOA_Post_Lvl_Ind', 'SOA_Antp_Lvl_TP', 'SOA_Guar_Lvl_TP'\n",
                "]\n",
                "FEATURES = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
                "\n",
                "# Sample for analysis\n",
                "np.random.seed(42)\n",
                "sample_size = min(10000, len(df))\n",
                "sample_idx = np.random.choice(len(df), size=sample_size, replace=False)\n",
                "X_sample = df[FEATURES].iloc[sample_idx].copy()\n",
                "\n",
                "# Convert categorical features to category dtype (matching training)\n",
                "for col in CATEGORICAL_FEATURES:\n",
                "    X_sample[col] = X_sample[col].astype('category')\n",
                "\n",
                "print(f'Sample size: {len(X_sample)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature importance\n",
                "feature_names = model.feature_name()\n",
                "importance_gain = model.feature_importance(importance_type='gain')\n",
                "importance_split = model.feature_importance(importance_type='split')\n",
                "\n",
                "# Create DataFrame\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': feature_names,\n",
                "    'Gain': importance_gain,\n",
                "    'Split': importance_split,\n",
                "    'Gain_Pct': importance_gain / importance_gain.sum() * 100,\n",
                "    'Split_Pct': importance_split / importance_split.sum() * 100\n",
                "}).sort_values('Gain', ascending=False)\n",
                "\n",
                "# Plot\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# Gain importance\n",
                "ax = axes[0]\n",
                "colors = plt.cm.Blues(np.linspace(0.4, 1.0, len(importance_df)))\n",
                "bars = ax.barh(importance_df['Feature'], importance_df['Gain_Pct'], color=colors[::-1])\n",
                "ax.set_xlabel('Importance (%)')\n",
                "ax.set_title('Feature Importance by Gain', fontweight='bold')\n",
                "ax.invert_yaxis()\n",
                "for bar, val in zip(bars, importance_df['Gain_Pct']):\n",
                "    ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, f'{val:.1f}%', va='center', fontsize=9)\n",
                "\n",
                "# Split importance\n",
                "ax = axes[1]\n",
                "importance_split_sorted = importance_df.sort_values('Split', ascending=False)\n",
                "colors = plt.cm.Greens(np.linspace(0.4, 1.0, len(importance_split_sorted)))\n",
                "bars = ax.barh(importance_split_sorted['Feature'], importance_split_sorted['Split_Pct'], color=colors[::-1])\n",
                "ax.set_xlabel('Importance (%)')\n",
                "ax.set_title('Feature Importance by Split Count', fontweight='bold')\n",
                "ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_feature_importance.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\nFeature Importance Table:')\n",
                "display(importance_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Tree Structure Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the first tree\n",
                "fig, ax = plt.subplots(figsize=(20, 12))\n",
                "lgb.plot_tree(model, tree_index=0, ax=ax, show_info=['split_gain', 'leaf_count'])\n",
                "ax.set_title('LightGBM Tree #1 Structure', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_tree_0.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multiple trees comparison\n",
                "fig, axes = plt.subplots(2, 2, figsize=(24, 16))\n",
                "\n",
                "tree_indices = [0, 10, 50, 100]\n",
                "for idx, tree_idx in enumerate(tree_indices):\n",
                "    ax = axes[idx // 2, idx % 2]\n",
                "    try:\n",
                "        lgb.plot_tree(model, tree_index=tree_idx, ax=ax)\n",
                "        ax.set_title(f'Tree #{tree_idx + 1}', fontsize=12, fontweight='bold')\n",
                "    except Exception as e:\n",
                "        ax.text(0.5, 0.5, f'Tree {tree_idx} not available', ha='center', va='center')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_trees_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Feature Contribution Analysis (SHAP-like)\n",
                "\n",
                "Using LightGBM's native `pred_contrib` for feature contributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use LightGBM native feature contributions (pred_contrib)\n",
                "# This is similar to SHAP but uses LightGBM's internal method\n",
                "\n",
                "# Get contributions for a sample\n",
                "contributions = model.predict(X_sample, pred_contrib=True)\n",
                "\n",
                "# contributions has shape (n_samples, n_features + 1)\n",
                "# Last column is the base value (expected value)\n",
                "print(f'Contributions shape: {contributions.shape}')\n",
                "print(f'Features: {len(FEATURES)}, Contributions columns: {contributions.shape[1]}')\n",
                "\n",
                "# Separate feature contributions and base value\n",
                "feature_contribs = contributions[:, :-1]\n",
                "base_value = contributions[:, -1].mean()\n",
                "\n",
                "print(f'Base value (expected prediction): {base_value:.6f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mean absolute contribution by feature (similar to SHAP bar plot)\n",
                "mean_abs_contrib = np.abs(feature_contribs).mean(axis=0)\n",
                "\n",
                "contrib_df = pd.DataFrame({\n",
                "    'Feature': FEATURES,\n",
                "    'Mean_Abs_Contribution': mean_abs_contrib\n",
                "}).sort_values('Mean_Abs_Contribution', ascending=True)\n",
                "\n",
                "# Plot\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "colors = plt.cm.Reds(np.linspace(0.4, 1.0, len(contrib_df)))\n",
                "ax.barh(contrib_df['Feature'], contrib_df['Mean_Abs_Contribution'], color=colors)\n",
                "ax.set_xlabel('Mean |Contribution|')\n",
                "ax.set_title('Feature Contributions (SHAP-like)', fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_feature_contributions.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\nFeature Contribution Ranking:')\n",
                "display(contrib_df.sort_values('Mean_Abs_Contribution', ascending=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature contribution vs feature value (like SHAP dependence plot)\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "top_features = ['Attained_Age', 'Duration', 'Issue_Age']\n",
                "for i, feature in enumerate(top_features):\n",
                "    ax = axes[i]\n",
                "    feat_idx = FEATURES.index(feature)\n",
                "    \n",
                "    # Get feature values and contributions\n",
                "    feat_values = X_sample[feature].values\n",
                "    feat_contribs = feature_contribs[:, feat_idx]\n",
                "    \n",
                "    # Scatter plot\n",
                "    scatter = ax.scatter(feat_values, feat_contribs, c=feat_contribs, \n",
                "                        cmap='RdBu_r', alpha=0.5, s=10)\n",
                "    ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
                "    ax.set_xlabel(feature)\n",
                "    ax.set_ylabel('Contribution')\n",
                "    ax.set_title(f'Contribution Dependence: {feature}', fontweight='bold')\n",
                "    plt.colorbar(scatter, ax=ax, label='Contribution')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_contribution_dependence.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Local Explanation (Individual Predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find high-risk and low-risk cases\n",
                "predictions = model.predict(X_sample)\n",
                "high_risk_idx = np.argmax(predictions)\n",
                "low_risk_idx = np.argmin(predictions)\n",
                "\n",
                "print('='*60)\n",
                "print('HIGH RISK CASE')\n",
                "print('='*60)\n",
                "print(f'Predicted mortality rate: {predictions[high_risk_idx]:.6f}')\n",
                "print(f'\\nFeature Values:')\n",
                "for feat in FEATURES:\n",
                "    print(f'  {feat}: {X_sample[feat].iloc[high_risk_idx]}')\n",
                "\n",
                "print('\\n' + '='*60)\n",
                "print('LOW RISK CASE')\n",
                "print('='*60)\n",
                "print(f'Predicted mortality rate: {predictions[low_risk_idx]:.6f}')\n",
                "print(f'\\nFeature Values:')\n",
                "for feat in FEATURES:\n",
                "    print(f'  {feat}: {X_sample[feat].iloc[low_risk_idx]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Waterfall plot for high-risk case\n",
                "def plot_waterfall(contributions, features, base_value, title, ax):\n",
                "    # Sort by absolute contribution\n",
                "    sorted_idx = np.argsort(np.abs(contributions))[::-1]\n",
                "    \n",
                "    # Prepare data\n",
                "    cumsum = base_value\n",
                "    colors = ['#E94F37' if c > 0 else '#2E86AB' for c in contributions[sorted_idx]]\n",
                "    \n",
                "    y_pos = np.arange(len(features))\n",
                "    ax.barh(y_pos, contributions[sorted_idx], color=colors, alpha=0.8)\n",
                "    ax.set_yticks(y_pos)\n",
                "    ax.set_yticklabels([features[i] for i in sorted_idx])\n",
                "    ax.axvline(0, color='gray', linestyle='-', alpha=0.5)\n",
                "    ax.set_xlabel('Contribution')\n",
                "    ax.set_title(title, fontweight='bold')\n",
                "    ax.invert_yaxis()\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# High risk\n",
                "plot_waterfall(feature_contribs[high_risk_idx], FEATURES, base_value, \n",
                "               f'High Risk Case (pred={predictions[high_risk_idx]:.4f})', axes[0])\n",
                "\n",
                "# Low risk\n",
                "plot_waterfall(feature_contribs[low_risk_idx], FEATURES, base_value, \n",
                "               f'Low Risk Case (pred={predictions[low_risk_idx]:.6f})', axes[1])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_local_explanations.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Partial Dependence Plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Partial dependence for numerical features with confidence bands\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for i, feature in enumerate(['Attained_Age', 'Duration', 'Issue_Age']):\n",
                "    ax = axes[i]\n",
                "    \n",
                "    feature_values = np.linspace(X_sample[feature].min(), X_sample[feature].max(), 50)\n",
                "    pdp_values = []\n",
                "    pdp_std = []\n",
                "    \n",
                "    for val in feature_values:\n",
                "        X_temp = X_sample.copy()\n",
                "        X_temp[feature] = val\n",
                "        preds = model.predict(X_temp)\n",
                "        pdp_values.append(preds.mean())\n",
                "        pdp_std.append(preds.std())\n",
                "    \n",
                "    pdp_values = np.array(pdp_values)\n",
                "    pdp_std = np.array(pdp_std)\n",
                "    \n",
                "    ax.plot(feature_values, pdp_values, linewidth=2, color='#E94F37', label='Mean')\n",
                "    ax.fill_between(feature_values, pdp_values - pdp_std, pdp_values + pdp_std, \n",
                "                    alpha=0.2, color='#E94F37', label='±1 Std')\n",
                "    ax.set_xlabel(feature)\n",
                "    ax.set_ylabel('Predicted Mortality Rate')\n",
                "    ax.set_title(f'Partial Dependence: {feature}', fontweight='bold')\n",
                "    ax.legend(loc='upper left')\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_partial_dependence.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. 2D Interaction Effect"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2D Partial Dependence (Age x Duration)\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "\n",
                "age_range = np.linspace(30, 80, 20)\n",
                "duration_range = np.linspace(1, 25, 20)\n",
                "\n",
                "pdp_2d = np.zeros((len(age_range), len(duration_range)))\n",
                "\n",
                "for i, age in enumerate(age_range):\n",
                "    for j, dur in enumerate(duration_range):\n",
                "        X_temp = X_sample.iloc[:100].copy()\n",
                "        X_temp['Attained_Age'] = age\n",
                "        X_temp['Duration'] = dur\n",
                "        pdp_2d[i, j] = model.predict(X_temp).mean()\n",
                "\n",
                "im = ax.contourf(duration_range, age_range, pdp_2d, levels=20, cmap='RdYlBu_r')\n",
                "plt.colorbar(im, ax=ax, label='Predicted Mortality Rate')\n",
                "ax.set_xlabel('Duration')\n",
                "ax.set_ylabel('Attained Age')\n",
                "ax.set_title('2D Partial Dependence: Age × Duration', fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_2d_pdp.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Categorical Feature Impact"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "cat_features = ['Sex', 'Smoker_Status', 'Insurance_Plan', 'Preferred_Class']\n",
                "\n",
                "for idx, feature in enumerate(cat_features):\n",
                "    ax = axes[idx // 2, idx % 2]\n",
                "    \n",
                "    categories = X_sample[feature].cat.categories\n",
                "    mean_preds = []\n",
                "    std_preds = []\n",
                "    \n",
                "    for cat in categories:\n",
                "        mask = X_sample[feature] == cat\n",
                "        if mask.sum() > 0:\n",
                "            preds = model.predict(X_sample[mask])\n",
                "            mean_preds.append(preds.mean())\n",
                "            std_preds.append(preds.std())\n",
                "        else:\n",
                "            mean_preds.append(0)\n",
                "            std_preds.append(0)\n",
                "    \n",
                "    bars = ax.bar(range(len(categories)), mean_preds, yerr=std_preds, \n",
                "                  color='#2E86AB', alpha=0.8, capsize=3)\n",
                "    ax.set_xticks(range(len(categories)))\n",
                "    ax.set_xticklabels([str(c)[:12] for c in categories], rotation=45, ha='right')\n",
                "    ax.set_xlabel(feature)\n",
                "    ax.set_ylabel('Mean Predicted Mortality Rate')\n",
                "    ax.set_title(f'Mortality by {feature}', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_categorical_impact.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Year Trend Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "\n",
                "ax.plot(year_factors['Year'], year_factors['Year_Factor'], \n",
                "        marker='o', markersize=10, linewidth=2, color='#2E86AB')\n",
                "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.7, label='Baseline (1.0)')\n",
                "ax.fill_between(year_factors['Year'], 1.0, year_factors['Year_Factor'], \n",
                "                alpha=0.3, color='#2E86AB')\n",
                "\n",
                "ax.set_xlabel('Observation Year')\n",
                "ax.set_ylabel('Year Factor (Multiplicative)')\n",
                "ax.set_title('Mortality Year Trend Factors', fontweight='bold')\n",
                "ax.set_ylim(0.95, 1.05)\n",
                "ax.legend()\n",
                "\n",
                "for _, row in year_factors.iterrows():\n",
                "    ax.annotate(f\"{row['Year_Factor']:.3f}\", \n",
                "                (row['Year'], row['Year_Factor']),\n",
                "                textcoords='offset points', xytext=(0, 10), ha='center', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_year_factors.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 9. Model Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prediction distribution\n",
                "predictions = model.predict(X_sample)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax = axes[0]\n",
                "ax.hist(predictions, bins=50, color='#2E86AB', alpha=0.7, edgecolor='black')\n",
                "ax.axvline(predictions.mean(), color='red', linestyle='--', label=f'Mean: {predictions.mean():.4f}')\n",
                "ax.axvline(np.median(predictions), color='green', linestyle='--', label=f'Median: {np.median(predictions):.4f}')\n",
                "ax.set_xlabel('Predicted Mortality Rate')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.set_title('Distribution of Predictions', fontweight='bold')\n",
                "ax.legend()\n",
                "\n",
                "ax = axes[1]\n",
                "ax.hist(np.log10(predictions + 1e-10), bins=50, color='#E94F37', alpha=0.7, edgecolor='black')\n",
                "ax.set_xlabel('Log10(Predicted Mortality Rate)')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.set_title('Distribution of Predictions (Log Scale)', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/plots/lgbm_prediction_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 10. Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('='*70)\n",
                "print('LGBM MODEL EXPLAINABILITY SUMMARY')\n",
                "print('='*70)\n",
                "print(f'\\nModel: Offset Poisson LightGBM')\n",
                "print(f'Number of trees: {model.num_trees()}')\n",
                "print(f'Number of features: {len(FEATURES)}')\n",
                "\n",
                "print(f'\\n--- Top 3 Features by Importance (Gain) ---')\n",
                "for _, row in importance_df.head(3).iterrows():\n",
                "    print(f\"  {row['Feature']}: {row['Gain_Pct']:.1f}%\")\n",
                "\n",
                "print(f'\\n--- Top 3 Features by Contribution ---')\n",
                "for _, row in contrib_df.sort_values('Mean_Abs_Contribution', ascending=False).head(3).iterrows():\n",
                "    print(f\"  {row['Feature']}: {row['Mean_Abs_Contribution']:.4f}\")\n",
                "\n",
                "print(f'\\n--- Prediction Statistics ---')\n",
                "print(f'  Mean: {predictions.mean():.6f}')\n",
                "print(f'  Median: {np.median(predictions):.6f}')\n",
                "print(f'  Std: {predictions.std():.6f}')\n",
                "print(f'  Range: [{predictions.min():.6f}, {predictions.max():.6f}]')\n",
                "\n",
                "print(f'\\n--- Year Factor Range ---')\n",
                "print(f'  Min: {year_factors[\"Year_Factor\"].min():.4f}')\n",
                "print(f'  Max: {year_factors[\"Year_Factor\"].max():.4f}')\n",
                "\n",
                "print(f'\\n--- Plots Saved (../data/plots/) ---')\n",
                "plots = [\n",
                "    'lgbm_feature_importance.png',\n",
                "    'lgbm_tree_0.png', 'lgbm_trees_comparison.png',\n",
                "    'lgbm_feature_contributions.png', 'lgbm_contribution_dependence.png',\n",
                "    'lgbm_local_explanations.png', 'lgbm_partial_dependence.png',\n",
                "    'lgbm_2d_pdp.png', 'lgbm_categorical_impact.png',\n",
                "    'lgbm_year_factors.png', 'lgbm_prediction_distribution.png'\n",
                "]\n",
                "for p in plots:\n",
                "    print(f'  ✓ {p}')\n",
                "\n",
                "print('='*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}